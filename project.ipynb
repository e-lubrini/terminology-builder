{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import requests\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "import sklearn_crfsuite\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.symbols import ORTH\n",
    "from spacy.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminology Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tree Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, name = None):\n",
    "        self.name = name\n",
    "        self.points_to = dict()\n",
    "        self.stored_value = None \n",
    "        \n",
    "        self.visited = False #for searching\n",
    "\n",
    "    def point_to_node(self, other_node):\n",
    "        self.points_to[other_node.name] = other_node\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.points_to == dict()\n",
    "    \n",
    "    def is_empty(self):\n",
    "        return (self.stored_value is None)\n",
    "    \n",
    "    def list_children_names(self):\n",
    "        return self.points_to.keys()\n",
    "    \n",
    "    def list_children(self):\n",
    "        self.points_to.values()\n",
    "    \n",
    "    def list_values_in_children(self):\n",
    "        stored_values = []\n",
    "        \n",
    "        if not self.is_empty():\n",
    "            stored_values.append(self.stored_value)\n",
    "\n",
    "        if self.is_leaf():\n",
    "            return stored_values\n",
    "        \n",
    "        for node in self.points_to.values():\n",
    "            stored_values.extend(\n",
    "                node.list_values_in_children()\n",
    "            )\n",
    "        return stored_values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TerminologyTree():\n",
    "    def __init__(self, name = \"\", root = Node() ):\n",
    "        self.name = name\n",
    "        self.root = root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_term_to_tree(term, tree):\n",
    "\n",
    "    current_node = tree.root\n",
    "    for word in term:\n",
    "        #go to the next node\n",
    "\n",
    "            # if there is no next node, create it\n",
    "        if word not in current_node.points_to.keys():\n",
    "            new_node = Node(word)\n",
    "            current_node.points_to[word] = new_node\n",
    "        else:\n",
    "            new_node = current_node.points_to[word]\n",
    "    \n",
    "        current_node = new_node\n",
    "\n",
    "    #now we are at the end of a path whose nodes spell the term\n",
    "\n",
    "    #store the string in the end node\n",
    "    current_node.stored_value = term\n",
    "\n",
    "\n",
    "def fill_terminology_tree(term_list, tree):\n",
    "    for term in term_list:\n",
    "        add_term_to_tree(term, tree)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(nlp = spacy.load(\"en_core_web_sm\")):\n",
    "    \n",
    "    special_case = [{ORTH: \"<bos>\"}]\n",
    "    nlp.tokenizer.add_special_case(\"<bos>\", special_case)\n",
    "\n",
    "    special_case = [{ORTH: \"<eos>\"}]\n",
    "    nlp.tokenizer.add_special_case(\"<eos>\", special_case)\n",
    "\n",
    "    infixes = list([r\"'s\\b\", r\"(?<!\\d)\\.(?!\\d)\"]) +  nlp.Defaults.prefixes\n",
    "    infix_re = spacy.util.compile_infix_regex(infixes)\n",
    "    nlp.tokenizer.infix_finditer = infix_re.finditer\n",
    "    \n",
    "    return Tokenizer(nlp.vocab, infix_finditer=infix_re.finditer)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticlesExtraction:\n",
    "    def __init__(self, number=20, verbose=True, save_txt=True, save_pdf=True):\n",
    "        self.number = number\n",
    "        self.verbose = verbose\n",
    "        self.save_txt = save_txt\n",
    "        self.save_pdf = save_pdf\n",
    "\n",
    "    def _get_links(self):\n",
    "        if self.verbose:\n",
    "            print(f'Getting the links for {self.number} articles...')\n",
    "        mainpage = requests.get('https://as-botanicalstudies.springeropen.com/articles')\n",
    "        mainsoup = BeautifulSoup(mainpage.text)\n",
    "        links = ['https://as-botanicalstudies.springeropen.com' + x['href'] for x in\n",
    "                 sum([x.findAll('a') for x in mainsoup.findAll('h3', class_=\"c-listing__title\")], [])]\n",
    "        return links[:self.number]\n",
    "\n",
    "    def extract(self):\n",
    "        extra = ['Availability of data and materials', 'Abbreviations', 'References', 'Acknowledgements',\n",
    "                 'Funding', 'Author information', 'Ethics declarations', 'Additional information',\n",
    "                 'Rights and permissions', 'About this article']\n",
    "        links = self._get_links()\n",
    "        pdf_links = []\n",
    "        if self.verbose:\n",
    "            print('Getting the texts...')\n",
    "        texts = dict()\n",
    "        for num, link in enumerate(links):\n",
    "            if self.verbose:\n",
    "                print(f'{num + 1}/{len(links)} links', end=\"\\r\")\n",
    "            page = requests.get(link)\n",
    "            pagecontent = BeautifulSoup(page.text)\n",
    "            name = pagecontent.findAll('h1', class_=\"c-article-title\")[0].text\n",
    "            text = \"\\n\".join(sum([list(map(lambda y: y.text, x.findAll('p'))) for x in pagecontent.findAll('section') if\n",
    "                                  x.has_attr('data-title') and x['data-title'] not in extra], []))\n",
    "            texts[name] = text\n",
    "            pdf_link = [x.findAll('a') for x in pagecontent.findAll('div', class_=\"c-pdf-download u-clear-both\")][0][0][\n",
    "                'href']\n",
    "            pdf_links.append(pdf_link)\n",
    "        if self.save_txt:\n",
    "            if self.verbose:\n",
    "                print('Saving the articles in txt...')\n",
    "            if not os.path.exists('articles'):\n",
    "                os.mkdir('articles')\n",
    "            for key, value in texts.items():\n",
    "                with open(f\"articles/{key.replace('/', '|')}.txt\", 'w') as file:\n",
    "                    file.write(value)\n",
    "        if self.save_pdf:\n",
    "            if self.verbose:\n",
    "                print('Saving the articles in pdf...')\n",
    "            if not os.path.exists('articles_pdf'):\n",
    "                os.mkdir('articles_pdf')\n",
    "            for (key, value), link in zip(texts.items(), pdf_links):\n",
    "                pdf = requests.get('https:' + link, allow_redirects=True)\n",
    "                open(f\"articles_pdf/{key.replace('/', '|')}.pdf\", 'wb').write(pdf.content)\n",
    "        return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleBasedExtractor:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.matcher = Matcher(self.nlp.vocab)\n",
    "\n",
    "    def extract(self, texts):\n",
    "        all_terms = []\n",
    "        self._add_rules()\n",
    "        for num, text in enumerate(texts):\n",
    "            doc = self.nlp(text)\n",
    "            matches = self.matcher(doc)\n",
    "            for match_id, start, end in matches:\n",
    "                string_id = self.nlp.vocab.strings[match_id]\n",
    "                span = doc[start:end]\n",
    "                lemma = ' '.join([n.lemma_ for n in self.nlp(span.text.lower())])\n",
    "                all_terms.append(lemma)\n",
    "\n",
    "            print(f'{num + 1}/{len(texts)} texts processed', end=\"\\r\")\n",
    "        return all_terms\n",
    "\n",
    "    def _add_rules(self):\n",
    "        noun_pattern = {\"POS\": {\"IN\": [\"NOUN\", \"PROPN\"]}}\n",
    "        det_pattern = {\"POS\": {\"IN\": [\"DET\", \"PRON\"]}, \"OP\": \"?\"}\n",
    "        pattern = [  #[{\"POS\": \"NOUN\"}, {\"POS\": \"NOUN\"}],\n",
    "            [noun_pattern, noun_pattern],\n",
    "            #[{\"DEP\": \"compound\"}, {\"POS\": \"NOUN\"}],\n",
    "            [noun_pattern, {\"POS\": \"ADP\"}, noun_pattern],\n",
    "            [{\"POS\": \"ADJ\", \"OP\": \"+\"}, noun_pattern],\n",
    "            [noun_pattern, {\"POS\": \"ADP\"}, det_pattern, noun_pattern],\n",
    "            [det_pattern, {\"POS\": \"ADJ\"}, {\"POS\": \"CCONJ\"}, {\"POS\": \"ADJ\"}, noun_pattern],\n",
    "        ]\n",
    "        self.matcher.add(\"terms\", pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Annotator:\n",
    "    tagging = dict()\n",
    "    def __init__(self):        \n",
    "        self.nlp = custom_tokenizer(nlp)\n",
    "\n",
    "    def _longest_term(self, position, word_list, tree):\n",
    "        current_node  = tree.root\n",
    "        term = []\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                word = word_list[position]\n",
    "                current_node = current_node.points_to[word]\n",
    "                if not current_node.is_empty(): \n",
    "                    aux_term = current_node.stored_value\n",
    "                    if len(aux_term) > len(term): term = aux_term\n",
    "                position += 1\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        return term\n",
    "\n",
    "\n",
    "\n",
    "    def annotate(self, tree, word_list):\n",
    "        \"\"\"\"\n",
    "        returns a list of tuples (word, tag)\n",
    "        \"\"\"\n",
    "        tagging = dict()\n",
    "        position = 0\n",
    "\n",
    "        def put_tag(position, tag):\n",
    "            tagging[str(position)]= tag\n",
    "            return None\n",
    "\n",
    "        while position < len(word_list):\n",
    "            #find the longest term appearing in the text at this position\n",
    "            term = self._longest_term(position, word_list, tree)\n",
    "            \n",
    "            length = len(term)\n",
    "\n",
    "            if length == 0: # no term was found\n",
    "                put_tag(position, \"O\")\n",
    "                position += 1\n",
    "            else:\n",
    "                put_tag(position, \"B\") #beginning of term\n",
    "                for i in range(length-1):\n",
    "                    put_tag(position + i +1, \"I\") #inside of term\n",
    "                position += length\n",
    "\n",
    "        text_tags = [\n",
    "            (word_list[position], tagging[str(position)])\n",
    "            for position in range(len(word_list))\n",
    "        ]\n",
    "\n",
    "        return text_tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def word2features(self, sent, i):\n",
    "        word = sent[i][0]\n",
    "        postag = sent[i][1]\n",
    "\n",
    "        features = {\n",
    "            'bias': 1.0,\n",
    "            'word.lower()': word.lower(),\n",
    "            'word[-3:]': word[-3:],\n",
    "            'word[-2:]': word[-2:],\n",
    "            'word.isupper()': word.isupper(),\n",
    "            'word.istitle()': word.istitle(),\n",
    "            'word.isdigit()': word.isdigit(),\n",
    "            'postag': postag,\n",
    "            'postag[:2]': postag[:2],\n",
    "        }\n",
    "        if i > 0:\n",
    "            word1 = sent[i - 1][0]\n",
    "            postag1 = sent[i - 1][1]\n",
    "            features.update({\n",
    "                '-1:word.lower()': word1.lower(),\n",
    "                '-1:word.istitle()': word1.istitle(),\n",
    "                '-1:word.isupper()': word1.isupper(),\n",
    "                '-1:postag': postag1,\n",
    "                '-1:postag[:2]': postag1[:2],\n",
    "            })\n",
    "        else:\n",
    "            features['BOS'] = True\n",
    "\n",
    "        if i < len(sent) - 1:\n",
    "            word1 = sent[i + 1][0]\n",
    "            postag1 = sent[i + 1][1]\n",
    "            features.update({\n",
    "                '+1:word.lower()': word1.lower(),\n",
    "                '+1:word.istitle()': word1.istitle(),\n",
    "                '+1:word.isupper()': word1.isupper(),\n",
    "                '+1:postag': postag1,\n",
    "                '+1:postag[:2]': postag1[:2],\n",
    "            })\n",
    "        else:\n",
    "            features['EOS'] = True\n",
    "\n",
    "        return features\n",
    "\n",
    "    def sent2features(self, sent):\n",
    "        return [self.word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "    def sent2labels(self, sent):\n",
    "        return [label for token, postag, label in sent]\n",
    "\n",
    "    def sent2tokens(self, sent):\n",
    "        return [token for token, postag, label in sent]\n",
    "\n",
    "    def convert_corpus(self, sents):\n",
    "        X = [self.sent2features(s) for s in sents]\n",
    "        y = [self.sent2labels(s) for s in sents]\n",
    "        return X, y\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "\n",
    "        crf = sklearn_crfsuite.CRF(\n",
    "            algorithm='lbfgs',\n",
    "            c1=0.1,\n",
    "            c2=0.1,\n",
    "            max_iterations=100,\n",
    "            all_possible_transitions=True)\n",
    "        crf.fit(X_train, y_train)\n",
    "        return crf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the links for 20 articles...\n",
      "Getting the texts...\n"
     ]
    }
   ],
   "source": [
    "artextr = ArticlesExtraction(20, save_txt=False, save_pdf=False)\n",
    "articles = artextr.extract()\n",
    "texts = [x for x in list(articles.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['world experience', 'modern assessment', 'assessment of the flora', 'many group', 'group of fungi', 'endophyte in plant', 'undiscovered bioactive', 'bioactive compo', '/micro', 'macro / micro', 'micro-', '-morphology', 'morphology of nutlet', 'boraginaceae family', 'salt stress', 'abiotic stress', 'major abiotic stress', 'plant growth', 'obligate mutualism', 'mutualism between fig', 'fig tree', 'symbiotic germination', 'mycorrhizal fungi', 'orchid from seed', 'seed in vit', 'agricultural management', 'temporal change', 'climate condition', 'soil property', 'tropical asia', 'gardnerianum sheph', 'ex ker', 'ker gawl', 'alien specie', 'invasive alien specie', 'bad invasive alien specie', 'seed during ingestion', 'avian frugivore', 'new lighting', 'light technology', 'soil quality', 'health of the tea', 'tea plantation', 'agriculture management', 'management practice', 'sweet potato', 'white sweet potato', 'l. simon', 'simon no', 'no .', 'beneficial effect', 'potential beneficial effect', 'many potential beneficial effect', 'vanilla planifolia', 'tropical orchid', 'important tropical orchid', 'orchid for production', 'natural vanilla', 'vanilla flavor', 'antimicrobial peptide', 'ornamental plant', 'important ornamental plant', 'significant rol', 'seed dispersal', 'new habitat', 'significant influence', 'influence on plant', 'plant dis', 'weedy rice', 'weedy counterpart', 'conspecific weedy counterpart', 'oryza sativa', 'sativa l.', 'medicinal plant', 'plant in taiwan', 'international market', 'market competition', 'southeast asia', 'tropical africa', 'south india', 'sri lanka']\n"
     ]
    }
   ],
   "source": [
    "r = RuleBasedExtractor()\n",
    "all_t = r.extract(texts)\n",
    "print(all_t)\n",
    "terminology = [t.split(' ') for t in all_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_terms = Counter([x.lower() for x in all_t]).most_common(100000)\n",
    "with open('popular_terms.txt', 'w') as file:\n",
    "    for line in popular_terms:\n",
    "        file.write(line[0] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tree Representation for Terminology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = TerminologyTree()\n",
    "fill_terminology_tree(terminology, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Based', 'O'),\n",
       "  ('on', 'O'),\n",
       "  ('world', 'O'),\n",
       "  ('experience,', 'O'),\n",
       "  ('first,', 'O'),\n",
       "  ('a', 'O'),\n",
       "  ('modern', 'B'),\n",
       "  ('assessment', 'I'),\n",
       "  ('of', 'O'),\n",
       "  ('the', 'O'),\n",
       "  ('flora', 'O'),\n",
       "  ('is', 'O'),\n",
       "  ('needed', 'O'),\n",
       "  ('to', 'O'),\n",
       "  ('develop', 'O'),\n",
       "  ('strategies', 'O'),\n",
       "  ('f', 'O')],\n",
       " [('Many', 'O'),\n",
       "  ('groups', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('fungi', 'O'),\n",
       "  ('live', 'O'),\n",
       "  ('as', 'O'),\n",
       "  ('an', 'O'),\n",
       "  ('endophyte', 'O'),\n",
       "  ('in', 'O'),\n",
       "  ('plants.', 'O'),\n",
       "  ('Both', 'O'),\n",
       "  ('published', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('undiscovered', 'B'),\n",
       "  ('bioactive', 'I'),\n",
       "  ('compo', 'O')],\n",
       " [('The', 'O'),\n",
       "  ('macro/micro-morphology', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('nutlets', 'O'),\n",
       "  ('in', 'O'),\n",
       "  ('11', 'O'),\n",
       "  ('species', 'O'),\n",
       "  ('(and', 'O'),\n",
       "  ('22', 'O'),\n",
       "  ('accessions)', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('the', 'O'),\n",
       "  ('Boraginaceae', 'O'),\n",
       "  ('family', 'O'),\n",
       "  ('w', 'O')],\n",
       " [('Salt', 'O'),\n",
       "  ('stress', 'O'),\n",
       "  ('is', 'O'),\n",
       "  ('a', 'O'),\n",
       "  ('major', 'B'),\n",
       "  ('abiotic', 'I'),\n",
       "  ('stress', 'I'),\n",
       "  ('that', 'O'),\n",
       "  ('limits', 'O'),\n",
       "  ('plant', 'O'),\n",
       "  ('growth,', 'O'),\n",
       "  ('development', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('productivity.', 'O'),\n",
       "  ('Studyi', 'O')],\n",
       " [('The', 'O'),\n",
       "  ('obligate', 'B'),\n",
       "  ('mutualism', 'I'),\n",
       "  ('between', 'O'),\n",
       "  ('fig', 'O'),\n",
       "  ('trees', 'O'),\n",
       "  ('(Ficus,', 'O'),\n",
       "  ('Moraceae)', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('pollinating', 'O'),\n",
       "  ('fig', 'O'),\n",
       "  ('wasps', 'O'),\n",
       "  ('(Agaonidae)', 'O'),\n",
       "  ('is', 'O'),\n",
       "  ('', 'O')],\n",
       " [('The', 'O'),\n",
       "  ('technique', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('symbiotic', 'O'),\n",
       "  ('germinationâ€”using', 'O'),\n",
       "  ('mycorrhizal', 'B'),\n",
       "  ('fungi', 'I'),\n",
       "  ('to', 'O'),\n",
       "  ('propagate', 'O'),\n",
       "  ('orchids', 'O'),\n",
       "  ('from', 'O'),\n",
       "  ('seed', 'B'),\n",
       "  ('in', 'I'),\n",
       "  ('vit', 'I')],\n",
       " [('Agricultural', 'O'),\n",
       "  ('management', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('temporal', 'B'),\n",
       "  ('change', 'I'),\n",
       "  ('including', 'O'),\n",
       "  ('climate', 'O'),\n",
       "  ('conditions', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('soil', 'O'),\n",
       "  ('properties', 'O'),\n",
       "  ('can', 'O'),\n",
       "  ('res', 'O')],\n",
       " [('Bamboos,', 'O'),\n",
       "  ('widely', 'O'),\n",
       "  ('distributed', 'O'),\n",
       "  ('in', 'O'),\n",
       "  ('temperate', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('tropical', 'O'),\n",
       "  ('Asia,', 'O'),\n",
       "  ('Africa', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('America,', 'O'),\n",
       "  ('refer', 'O'),\n",
       "  ('to', 'O'),\n",
       "  ('a', 'O'),\n",
       "  ('group', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('', 'O')],\n",
       " [('Hedychium', 'O'),\n",
       "  ('gardnerianum', 'O'),\n",
       "  ('Sheph.', 'O'),\n",
       "  ('ex', 'O'),\n",
       "  ('Ker', 'O'),\n",
       "  ('Gawl.', 'O'),\n",
       "  ('is', 'O'),\n",
       "  ('one', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('the', 'O'),\n",
       "  ('100', 'O'),\n",
       "  (\"world's\", 'O'),\n",
       "  ('worst', 'O'),\n",
       "  ('invasive', 'O'),\n",
       "  ('alien', 'O'),\n",
       "  ('species', 'O'),\n",
       "  ('an', 'O')],\n",
       " [('By', 'O'),\n",
       "  ('transporting', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('scarifying', 'O'),\n",
       "  ('the', 'O'),\n",
       "  ('seeds', 'O'),\n",
       "  ('during', 'O'),\n",
       "  ('ingestion,', 'O'),\n",
       "  ('avian', 'O'),\n",
       "  ('frugivores', 'O'),\n",
       "  ('reduce', 'O'),\n",
       "  ('the', 'O'),\n",
       "  ('competition', 'O'),\n",
       "  ('w', 'O')],\n",
       " [('Nowadays,', 'O'),\n",
       "  ('light-emitting', 'O'),\n",
       "  ('diodes', 'O'),\n",
       "  ('(LEDs)', 'O'),\n",
       "  ('as', 'O'),\n",
       "  ('a', 'O'),\n",
       "  ('new', 'B'),\n",
       "  ('lighting', 'I'),\n",
       "  ('technology,', 'O'),\n",
       "  ('have', 'O'),\n",
       "  ('been', 'O'),\n",
       "  ('emerged', 'O'),\n",
       "  ('as', 'O'),\n",
       "  ('an', 'O'),\n",
       "  ('alterna', 'O')],\n",
       " [('The', 'O'),\n",
       "  ('soil', 'B'),\n",
       "  ('quality', 'I'),\n",
       "  ('and', 'O'),\n",
       "  ('health', 'B'),\n",
       "  ('of', 'I'),\n",
       "  ('the', 'I'),\n",
       "  ('tea', 'I'),\n",
       "  ('plantations', 'O'),\n",
       "  ('are', 'O'),\n",
       "  ('dependent', 'O'),\n",
       "  ('on', 'O'),\n",
       "  ('agriculture', 'B'),\n",
       "  ('management', 'I'),\n",
       "  ('practices', 'O')],\n",
       " [('White', 'O'),\n",
       "  ('sweet', 'B'),\n",
       "  ('potato', 'I'),\n",
       "  ('(WSP;', 'O'),\n",
       "  ('Ipomoea', 'O'),\n",
       "  ('batatas', 'O'),\n",
       "  ('L.', 'O'),\n",
       "  ('Simon', 'O'),\n",
       "  ('No.', 'O'),\n",
       "  ('1)', 'O'),\n",
       "  ('has', 'O'),\n",
       "  ('many', 'O'),\n",
       "  ('potential', 'O'),\n",
       "  ('beneficial', 'O'),\n",
       "  ('effects', 'O'),\n",
       "  ('on', 'O'),\n",
       "  ('me', 'O')],\n",
       " [('Vanilla', 'O'),\n",
       "  ('planifolia', 'O'),\n",
       "  ('is', 'O'),\n",
       "  ('an', 'O'),\n",
       "  ('important', 'B'),\n",
       "  ('tropical', 'I'),\n",
       "  ('orchid', 'I'),\n",
       "  ('for', 'O'),\n",
       "  ('production', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('natural', 'B'),\n",
       "  ('vanilla', 'I'),\n",
       "  ('flavor.', 'O'),\n",
       "  ('Traditi', 'O')],\n",
       " [('Antimicrobial', 'O'),\n",
       "  ('peptides', 'O'),\n",
       "  ('(AMPs)', 'O'),\n",
       "  ('are', 'O'),\n",
       "  ('a', 'O'),\n",
       "  ('class', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('short,', 'O'),\n",
       "  ('usually', 'O'),\n",
       "  ('positively', 'O'),\n",
       "  ('charged', 'O'),\n",
       "  ('polypeptides', 'O'),\n",
       "  ('that', 'O'),\n",
       "  ('exi', 'O')],\n",
       " [('\\nPhalaenopsis', 'O'),\n",
       "  ('is', 'O'),\n",
       "  ('one', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('the', 'O'),\n",
       "  ('important', 'O'),\n",
       "  ('ornamental', 'O'),\n",
       "  ('plants', 'O'),\n",
       "  ('worldwide.', 'O'),\n",
       "  ('It', 'O'),\n",
       "  ('plays', 'O'),\n",
       "  ('the', 'O'),\n",
       "  ('most', 'O'),\n",
       "  ('significant', 'B'),\n",
       "  ('rol', 'I')],\n",
       " [('Seed', 'O'),\n",
       "  ('dispersal', 'O'),\n",
       "  ('allows', 'O'),\n",
       "  ('plants', 'O'),\n",
       "  ('to', 'O'),\n",
       "  ('colonize', 'O'),\n",
       "  ('new', 'O'),\n",
       "  ('habitats', 'O'),\n",
       "  ('that', 'O'),\n",
       "  ('has', 'O'),\n",
       "  ('an', 'O'),\n",
       "  ('significant', 'B'),\n",
       "  ('influence', 'I'),\n",
       "  ('on', 'O'),\n",
       "  ('plant', 'B'),\n",
       "  ('dis', 'I')],\n",
       " [('Weedy', 'O'),\n",
       "  ('rice,', 'O'),\n",
       "  ('a', 'O'),\n",
       "  ('conspecific', 'B'),\n",
       "  ('weedy', 'I'),\n",
       "  ('counterpart', 'I'),\n",
       "  ('of', 'O'),\n",
       "  ('the', 'O'),\n",
       "  ('cultivated', 'O'),\n",
       "  ('rice', 'O'),\n",
       "  ('(Oryza', 'O'),\n",
       "  ('sativa', 'O'),\n",
       "  ('L.),', 'O'),\n",
       "  ('has', 'O'),\n",
       "  ('been', 'O'),\n",
       "  ('probl', 'O')],\n",
       " [('Production', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('medicinal', 'O'),\n",
       "  ('plants', 'O'),\n",
       "  ('in', 'O'),\n",
       "  ('Taiwan', 'O'),\n",
       "  ('is', 'O'),\n",
       "  ('not', 'O'),\n",
       "  ('only', 'O'),\n",
       "  ('hampered', 'O'),\n",
       "  ('by', 'O'),\n",
       "  ('international', 'B'),\n",
       "  ('market', 'I'),\n",
       "  ('competition,', 'O'),\n",
       "  ('b', 'O')],\n",
       " [('Southeast', 'O'),\n",
       "  ('Asia,', 'O'),\n",
       "  ('together', 'O'),\n",
       "  ('with', 'O'),\n",
       "  ('tropical', 'O'),\n",
       "  ('Africa,', 'O'),\n",
       "  ('Madagascar,', 'O'),\n",
       "  ('South', 'O'),\n",
       "  ('India', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('Sri', 'O'),\n",
       "  ('Lanka,', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('the', 'O'),\n",
       "  ('easter', 'O')]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno = Annotator()\n",
    "annotations = [anno.annotate(tree, text.split(' ')) for text in texts]\n",
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('\\nPhalaenopsis', 'O'),\n",
       "  ('is', 'O'),\n",
       "  ('one', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('the', 'O'),\n",
       "  ('important', 'O'),\n",
       "  ('ornamental', 'O'),\n",
       "  ('plants', 'O'),\n",
       "  ('worldwide.', 'O'),\n",
       "  ('It', 'O'),\n",
       "  ('plays', 'O'),\n",
       "  ('the', 'O'),\n",
       "  ('most', 'O'),\n",
       "  ('significant', 'B'),\n",
       "  ('rol', 'I')],\n",
       " [('Seed', 'O'),\n",
       "  ('dispersal', 'O'),\n",
       "  ('allows', 'O'),\n",
       "  ('plants', 'O'),\n",
       "  ('to', 'O'),\n",
       "  ('colonize', 'O'),\n",
       "  ('new', 'O'),\n",
       "  ('habitats', 'O'),\n",
       "  ('that', 'O'),\n",
       "  ('has', 'O'),\n",
       "  ('an', 'O'),\n",
       "  ('significant', 'B'),\n",
       "  ('influence', 'I'),\n",
       "  ('on', 'O'),\n",
       "  ('plant', 'B'),\n",
       "  ('dis', 'I')],\n",
       " [('Weedy', 'O'),\n",
       "  ('rice,', 'O'),\n",
       "  ('a', 'O'),\n",
       "  ('conspecific', 'B'),\n",
       "  ('weedy', 'I'),\n",
       "  ('counterpart', 'I'),\n",
       "  ('of', 'O'),\n",
       "  ('the', 'O'),\n",
       "  ('cultivated', 'O'),\n",
       "  ('rice', 'O'),\n",
       "  ('(Oryza', 'O'),\n",
       "  ('sativa', 'O'),\n",
       "  ('L.),', 'O'),\n",
       "  ('has', 'O'),\n",
       "  ('been', 'O'),\n",
       "  ('probl', 'O')],\n",
       " [('Production', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('medicinal', 'O'),\n",
       "  ('plants', 'O'),\n",
       "  ('in', 'O'),\n",
       "  ('Taiwan', 'O'),\n",
       "  ('is', 'O'),\n",
       "  ('not', 'O'),\n",
       "  ('only', 'O'),\n",
       "  ('hampered', 'O'),\n",
       "  ('by', 'O'),\n",
       "  ('international', 'B'),\n",
       "  ('market', 'I'),\n",
       "  ('competition,', 'O'),\n",
       "  ('b', 'O')],\n",
       " [('Southeast', 'O'),\n",
       "  ('Asia,', 'O'),\n",
       "  ('together', 'O'),\n",
       "  ('with', 'O'),\n",
       "  ('tropical', 'O'),\n",
       "  ('Africa,', 'O'),\n",
       "  ('Madagascar,', 'O'),\n",
       "  ('South', 'O'),\n",
       "  ('India', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('Sri', 'O'),\n",
       "  ('Lanka,', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('the', 'O'),\n",
       "  ('easter', 'O')]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = [anno.annotate(tree=tree, word_list=text.split(' '))for text in texts[15:]]\n",
    "train = [anno.annotate(tree=tree, word_list=text.split(' '))for text in texts[:15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = SequenceClassifier()\n",
    "X_train, y_train = seq.convert_corpus(train)\n",
    "model = seq.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(model.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = seq.convert_corpus(test)\n",
    "y_pred = model.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
